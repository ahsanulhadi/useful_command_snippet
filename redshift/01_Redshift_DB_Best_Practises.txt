#########################################################################
Redshift Resources: * *
https://aws.amazon.com/redshift/developer-resources/

ADMIN SQL Views:
https://github.com/awslabs/amazon-redshift-utils/tree/master/src/AdminViews

ADMIN Scripts: 
https://github.com/awslabs/amazon-redshift-utils/tree/master/src/AdminScripts

Redshift API Reference:
http://docs.aws.amazon.com/redshift/latest/APIReference/Welcome.html

Tuning Queries:
http://docs.aws.amazon.com/redshift/latest/dg/c-optimizing-query-performance.html

Best Practises for Loading Data:
http://docs.aws.amazon.com/redshift/latest/dg/c_loading-data-best-practices.html

######################################################################


-- =======================================
-- BEST PRACTISES: TABLE DESIGN
-- =======================================
Source: http://docs.aws.amazon.com/redshift/latest/dg/c_designing-tables-best-practices.html

https://www.periscopedata.com/blog/disk-based-temporary-tables.html * * 

-- --------------------------------------------------------
-- How to select DIST STYLE for tables. / DISTKEY
-- --------------------------------------------------------
Source: http://www.matillion.com/redshift/aws-redshift-performance-choosing-the-right-distribution-styles/ 

Based on our extensive experience of using AWS Redshift, here are some tips for the best-practice use of distribution styles.

(1) All = We typically set the distribution style to ALL for smaller dimension tables, e.g. a date dimension with only a few thousand entries.
 -> A copy of the entire table is distributed to every node. Where EVEN distribution or KEY distribution place only a portion of a table's rows on each node, ALL distribution ensures that every row is collocated for every join that the table participates in.
 
(2) EVEN = We set EVEN for tables that are not joined with other tables or are only joined to tables with ALL style specified. For example, a fact table with joins to small dimensions (because each of the small dimensions is already set to ‘All’).

-> The leader node distributes the rows accross the slices in a round-robin fashion regardless the values in any column. It is appropriate when a table does not participate in joins or when there is not a clear choice between KEY distribution and ALL distribution. 

(3) KEY = And if we have a very large dimension we will DISTRIBUTE both the dimension and any fact associated with it on their join column. You can (currently) only optimise for a single large dimension, so if we have a second large dimension we would take the storage-hit and distribute ALL, or design the dimension columns into the fact.

-> Keyword that specifies that the column is the distribution key for the table. << ONLY ONE COLUMN in a table can be the distribution key >> The rows are distributed according to the values in one column. The leader node will attempt to place matching values on the same node slice. If you distribute a pair of tables on the joining keys, the leader node collocates the rows on the slices according to the values in the joining columns so that matching values from the common columns are physically stored together.
-- --------------------------------------------------------

When you execute a query, the query optimizer redistributes the rows to the compute nodes as needed to perform any joins and aggregations. 
The goal in selecting a table distribution style is to 'minimize the impact of the redistribution step by locating the data where it needs to be' before the query is executed.

(1) Distribute the fact table and one dimension table on their common columns.
Your fact table can have only one distribution key. Any tables that join on another key will not be collocated with the fact table. Choose one dimension to collocate based on how frequently it is joined and 
the size of the joining rows. << Designate both the dimension table's primary key and the fact table's corresponding foreign key as the DISTKEY. >>

<< Collocate data from joined tables as much as possible to avoid data broadcasting >>

(2) Choose the largest dimension based on the size of the filtered data set.
Only the rows that are used in the join need to be distributed, so consider the size of the of the data set after filtering, not the size of the table.

(3) Change some dimension tables to use ALL distribution.
If a dimension table cannot be collocated with the fact table or other important joining tables, you can improve query performance significantly by distributing the entire table to all of the nodes. 
Cons: Using ALL distribution multiplies storage space requirements and increases load times and maintenance operations, so you should weigh all factors before choosing ALL distribution.  


<< An even distribution of data on the cluster gives you the most parallel processing power. Choose a distribution style that ensures each compute node is processing a portion of the work in parallel. 
Joins and grouped aggregations will also benefit from planning ahead. 
Joins will always be faster if the tables being joined are distributed on the same key, so that all of the rows that need to be joined are collocated. 
Grouped aggregates will always be faster if each group's rows are collocated.>>


-- --------------------------------------------------------
-- Change DIST STYLE 
-- --------------------------------------------------------

-- Change DISTKEY/DISTSTYLE for existing table. 
BEGIN;

CREATE TABLE mytable_tmp
DISTSTYLE ALL -- You can also use DISTKEY(some_column) or DISTSTYLE EVEN
AS SELECT * FROM mytable;

DROP TABLE mytable;
ALTER TABLE mytable_tmp RENAME TO mytable;

COMMIT;
-- This allows you to easily modify the distkey or diststyle of a table without even knowing what columns are in that table. You only need to know the table's name.

-- -------------------------------------------
/*
SORT KEY = Keyword that specifies that the column is the sort key for the table. << You can define a maximum of 400 COMPOUND SORT-KEY columns or 8 INTERLEAVED SORT-KEY per table. >>
When data is loaded into the table, the data is sorted by one or more columns that are designated as sort keys. 
You can use the SORTKEY keyword after a column name to specify a SINGLE-COLUMN sort key, OR you can specify one or more columns as sort key columns for the table by using the SORTKEY (column_name [, ...]) syntax. Only compound sort keys are created with this syntax. If you do not specify any sort keys, the table is not sorted.  

*/

-- SORT KEY selection

Amazon Redshift stores your data on disk in sorted order according to the sort key. The Amazon Redshift query optimizer uses sort order when it determines optimal query plans.

(1) If recent data is queried most frequently, specify the timestamp column as the leading column for the sort key. 
Queries will be more efficient because they can skip entire blocks that fall outside the time range.

(2) If you do frequent range filtering or equality filtering on one column, specify that column as the sort key.  * *
Amazon Redshift can skip reading entire blocks of data for that column because it keeps track of the minimum and maximum column values stored on each block and can skip blocks that don't apply to the predicate range.

(3) If you frequently join a table, specify the join column as both the sort key and the distribution key. * * * 
This enables the query optimizer to choose a sort merge join instead of a slower hash join. Because the data is already sorted on the join key, the query optimizer can bypass the sort phase of the sort merge join.

<< Assign the appropriate sortkey for faster table scan >>

-- ---------------------------------------------------------------
-- Different SORT KEYS.

To-DO: 
https://blog.chartio.com/blog/understanding-interleaved-sort-keys-in-amazon-redshift-part-1
http://www.datasciencecentral.com/profiles/blogs/using-amazon-redshift-s-interleaved-sort-keys-for-35x-faster

http://docs.aws.amazon.com/redshift/latest/dg/t_Sorting_data-compare-sort-styles.html

(1) SINGLE COLUMN SORT KEY: 

(2) COMPOUND KEY: 
A compound sort key produces a sort order similar to that of the `order by` clause where the first column is sorted in its entirety, then within each first column grouping the second column is sorted in its entirety and so on until the entire key has been sorted. A compound sort key is most useful when a query scans rows according to the order of the sort columns. The performance benefits of sorting with a compound key decrease when queries rely on secondary sort columns.

(3) INTERLEAVED SORT KEY: 
Specifies that the data is sorted using an interleaved sort key. A maximum of eight columns can be specified for an interleaved sort key.
An interleaved sort gives equal weight to each column, or subset of columns, in the sort key, so queries do not depend on the order of the columns in the sort key. When a query uses one or more secondary sort columns, interleaved sorting significantly improves query performance. Interleaved sorting carries a small overhead cost for data loading and vacuuming operations.


-- -------------------------------------------
-- COMPRESSION 
Automatic compression produces the best results. Note: temporary tables are not compressed. 

-- -------------------------------------------
-- PRIMARY & FOREIGN KEY
Define primary key and foreign key constraints between tables wherever appropriate. Even though they are informational only, the query optimizer uses those constraints to generate more efficient query plans.

-- -------------------------------------------


-- =======================================
-- BEST PRACTISES: QUERY DESIGN
-- =======================================
Source: http://docs.aws.amazon.com/redshift/latest/dg/c_designing-queries-best-practices.html

(1) Avoid 'SELECT *'
(2) Use a CASE Expression to perform complex aggregations
(3) Don’t use cross-joins unless absolutely necessary.
(4) Use subqueries in cases where one table in the query is used only for predicate conditions.
(5) Use predicates to restrict the dataset as much as possible. In the predicate, use the least expensive operators. (expensive = 'LIKE', 'SIMILAR' ..etc) 
(6) Avoid using functions in query predicates.
(7) If possible, use a WHERE clause based on the << PRIMARY SORT COLUMN >> of the largest table in the query to restrict the dataset. The query planner can then use << ROW ORDER >> to help determine which records match the criteria, so it can skip scanning large numbers of disk blocks. Without this, the query execution engine must scan the entire table.
(8) Add predicates to filter other tables that participate in the join, << even when the predicates are redundant >>. Amazon Redshift can then efficiently skip scanning blocks from those tables. For example, suppose you want to join TAB1 and TAB2. The sort key for TAB1 is tab1.timestamp and the sort key for TAB2 is tab2.timestamp. 
 
SELECT * FROM tab1, tab2  WHERE tab1.key = tab2.key AND tab1.timestamp > '1/1/2013';

If the WHERE clause doesn't include a predicate for tab2.timestamp, the execution engine is forced to scan the entire table. If the join would result in values from tab2.timestamp2 also being greater than January 1, 2013, then add that filter also, even though it is redundant.

SELECT * FROM tab1, tab2 WHERE tab1.key = tab2.key and tab1.timestamp > '1/1/2013' and tab2.timestamp > '1/1/2013';

===============================================
Links:
===============================================

Redshift:
http://www.eshioji.co.uk/2013/07/a-simplistic-redshift-trouble-shooting.html * * *

https://www.quora.com/What-are-the-pros-and-cons-of-using-Amazon-Redshift

https://www.flydata.com/blog/when-should-you-consider-using-amazon-redshift/

http://dailytechnology.net/2013/08/03/redshift-what-you-need-to-know/

https://blogs.aws.amazon.com/bigdata/post/Tx1WZP38ERPGK5K/Optimizing-for-Star-Schemas-and-Interleaved-Sorting-on-Amazon-Redshift

https://amplitude.com/blog/2015/03/27/why-we-chose-redshift/

http://www.looker.com/blog/optimizing-redshift-for-analytics

http://stackoverflow.com/questions/26612932/querying-json-fields-in-redshift

https://www.sqlskills.com/blogs/jonathan/ctes-window-functions-and-views/

https://facility9.com/2008/12/a-quick-introduction-to-common-table-expressions-3/
 
http://engineeringblog.yelp.com/2015/01/title-ctes-and-window-functions-unleashing-the-power-of-redshift.html

https://www.sqlskills.com/blogs/jonathan/ctes-window-functions-and-views/

http://datapipelinearchitect.com/tools-for-combining-multiple-data-sources/
 
http://nerds.airbnb.com/airflow/

DWH:
http://www.1keydata.com/datawarehousing/concepts.html